{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcbc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b783d0c",
   "metadata": {},
   "source": [
    "Objective: Create an income, balancesheet, and cashflow file, each with tabs corresponding to their reporting periods:\n",
    "    e.g. Company A, if it has three reports, would have one file containing three tabs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26db144",
   "metadata": {},
   "source": [
    "Structure:\n",
    "\n",
    "<li>Create a list of companies to iterate over.</li>\n",
    "<li>Create a master file to write for each company</li>\n",
    "<li>Find the list of files associated with each company.</li>\n",
    "<li>Iterate over each file, appending each one to a new tab in the company's master file.</li>\n",
    "Rinse & Repeat.\n",
    "\n",
    "Formalized version:\n",
    "<li>Outer loop, looping through the list of companies</li>\n",
    "<li>Inner loop that loops through all the files for each company</li>\n",
    "<li>In the inner loop, append each file to a new tab in the master file</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d1ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_company_list():\n",
    "    companies = []\n",
    "    unique_list = []\n",
    "    file_list = glob.glob(\"C:/Users/curt.beck/Downloads/Cognaize/*.xlsx\")\n",
    "    for file in file_list:\n",
    "        match_obj = re.search(\"[A-Za-z]+\\_\\d+|[A-Za-z]+\\s+[\\&A-Za-z\\s\\_\\d]+\", file)\n",
    "        if match_obj is not None:\n",
    "            split_str = match_obj.group().split('_')\n",
    "            split_str_item = split_str[0]\n",
    "            companies.append(split_str_item)\n",
    "    \n",
    "    for company in companies:\n",
    "        if company not in unique_list:\n",
    "            unique_list.append(company)\n",
    "    no_spaces = [company.strip() for company in unique_list]\n",
    "    clean_list = [company for company in no_spaces if company]\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a91326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sheets(sheet_list, statement_type):\n",
    "    if statement_type == 'Income Statement':\n",
    "        filtered_list = [sheet for sheet in sheet_list if re.search('IS\\s+\\-\\s+\\d{1}', sheet)]\n",
    "        if len(filtered_list) > 0:\n",
    "            return filtered_list[0]\n",
    "        else:\n",
    "            return [] \n",
    "    elif statement_type == 'Balance Sheet':\n",
    "        filtered_list = [sheet for sheet in sheet_list if re.findall('BS\\s+\\-\\s+\\d{1}', sheet)]\n",
    "        if len(filtered_list) > 1:\n",
    "            return filtered_list\n",
    "        elif len(filtered_list) == 1:\n",
    "            return filtered_list[0]\n",
    "        else:\n",
    "            return []\n",
    "    elif statement_type == 'Cash Flow':\n",
    "        filtered_list = [sheet for sheet in sheet_list if re.search('CF\\s+\\-\\s+\\d{1}', sheet)]\n",
    "        if len(filtered_list) > 0:\n",
    "            return filtered_list[0]\n",
    "        else:\n",
    "            return []\n",
    "    #return filtered_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03f539",
   "metadata": {},
   "source": [
    "The create_lists function creates an exception file list, referring to companies with more than one file from the same period. This exception list will be used to help the program append two files together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdb2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists(companies):\n",
    "    exception_list = []\n",
    "    for company in companies:\n",
    "        master_file_list = glob.glob(f\"C:/Users/curt.beck/Downloads/Cognaize/*{company}*.xlsx\")\n",
    "        special_file_list = glob.glob(f\"C:/Users/curt.beck/Downloads/Cognaize/*{company}*[_][0-9].xlsx\")\n",
    "        for special_file in special_file_list:\n",
    "            original_file = special_file[0:-7] + \".xlsx\"\n",
    "            if original_file in master_file_list:\n",
    "                exception_list.append(original_file)\n",
    "    return exception_list     \n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80abd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mtd_ytd_value(file, sheet_name):\n",
    "    df = pd.read_excel(file, sheet_name='Metadata')\n",
    "    filtered_df = df.loc[df['Sheet name'] == sheet_name]\n",
    "    val_type = filtered_df['Value column 1 period coverage'].iloc[0]\n",
    "    if val_type == 'monthly':\n",
    "        val_type = 'mtd'\n",
    "    else:\n",
    "        val_type\n",
    "    return val_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11ab95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mtd_ytd_value2(file, sheet_name):\n",
    "    df = pd.read_excel(file, sheet_name='Metadata')\n",
    "    filtered_df = df.loc[df['Sheet name'] == sheet_name]\n",
    "    filtered_df = filtered_df.filter(regex=\"Value\\s+column\\s+\\d{1}\\s+period\\s+coverage\", axis=1).dropna(axis=1)\n",
    "    #if val_type == 'monthly':\n",
    "    #    val_type = 'mtd'\n",
    "    #else:\n",
    "    #    val_type\n",
    "    #return val_type\n",
    "    return list(filtered_df.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a46f8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_process(company, file, statement_type):\n",
    "    #i = 0\n",
    "    file_name = file[0:-5]\n",
    "    tab_name_match = re.search(\"\\_\\d+\", file).group().split('_')\n",
    "    tab_name = tab_name_match[-1]\n",
    "    sheet_names = pd.ExcelFile(file).sheet_names\n",
    "    sheet_name = filter_sheets(sheet_names, statement_type)\n",
    "    files = glob.glob(f\"{file_name}[_][0-9].xlsx\")\n",
    "    if len(files) == 1:\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "        if df.filter(regex=\"YTD|ytd|Ytd|MTD|Mtd|mtd|QTD|Qtd|Months|Jan|Feb|Mar|Apr|May|Jun|June|Jul|July|Aug|Sep|September|Oct|Nov|Dec\").empty:\n",
    "            ytd_mtd_col = get_mtd_ytd_value2(file, sheet_name)\n",
    "            i = 0\n",
    "            if len(ytd_mtd_col) == len(df.columns[1:]):\n",
    "                ytd_mtd_col.append(\"\")\n",
    "            for df_col in df.columns[1:]:\n",
    "                df.rename(columns={df_col: str(df_col) + ' ' + str(ytd_mtd_col[i])}, inplace=True)\n",
    "                i+=1\n",
    "            for df_col in df.columns:\n",
    "                match = re.search(\"\\.\\d{1}\", df_col)\n",
    "                if match is not None:\n",
    "                    val = match.group()\n",
    "                    replace_val  = df_col.replace(val, '')\n",
    "                    df.rename(columns={df_col : replace_val}, inplace=True)\n",
    "        sheet_nameslist_2 = pd.ExcelFile(files[0]).sheet_names\n",
    "        sheet_name_2 = filter_sheets(sheet_nameslist_2, statement_type)\n",
    "        df2 = pd.read_excel(files[0], sheet_name=sheet_name_2)\n",
    "        df2 = df2.iloc[:, 1:]\n",
    "        if df2.filter(regex=\"YTD|ytd|Ytd|MTD|Mtd|mtd|QTD|Qtd|Months|Jan|Feb|Mar|Apr|May|Jun|June|Jul|July|Aug|Sep|September|Oct|Nov|Dec\").empty:\n",
    "            ytd_mtd_col2 = get_mtd_ytd_value2(files[0], sheet_name_2)\n",
    "            i_2 = 0\n",
    "            if len(ytd_mtd_col2) != len(df2.columns):\n",
    "                ytd_mtd_col2.append(\"\")\n",
    "            for df2_col in df2.columns:\n",
    "                df2.rename(columns={df2_col: str(df2_col) + ' ' + str(ytd_mtd_col2[i_2])}, inplace=True)\n",
    "                i_2+=1\n",
    "            for df2_col in df2.columns:\n",
    "                match = re.search(\"\\.\\d{1}\", df2_col)\n",
    "                if match is not None:\n",
    "                    val = match.group()\n",
    "                    replace_val  = df2_col.replace(val, '')\n",
    "                    df2.rename(columns={df2_col : replace_val}, inplace=True)\n",
    "        concat_df = pd.concat([df, df2], axis=1)\n",
    "        \n",
    "        #final_df = concat_df.T.drop_duplicates().T\n",
    "        return concat_df, tab_name\n",
    "    elif len(files) > 1:\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "        sheet_nameslist_2 = pd.ExcelFile(files[0]).sheet_names\n",
    "        sheet_name_2 = filter_sheets(sheet_nameslist_2, statement_type)\n",
    "        sheet_nameslist_3 = pd.ExcelFile(files[1]).sheet_names\n",
    "        sheet_name_3 = filter_sheets(sheet_nameslist_3, statement_type)\n",
    "        df2 = pd.read_excel(files[0], sheet_name=sheet_name_2)\n",
    "        df2 = df2.iloc[:, 1:]\n",
    "        df3 = pd.read_excel(files[-1], sheet_name=sheet_name_3)\n",
    "        df3 = df3.iloc[:, 1:]\n",
    "        concat_df = pd.concat([df, df2, df3], axis=1)\n",
    "        for col\n",
    "        #final_df = concat_df.T.drop_duplicates().T\n",
    "        return concat_df, tab_name\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5e1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_balance_sht(file, sheets):\n",
    "    df1 = pd.read_excel(file, sheet_name=sheets[0], header=None)\n",
    "    df2 = pd.read_excel(file, sheet_name=sheets[-1], header=None, skiprows=1)\n",
    "    df2.dropna(inplace=True)\n",
    "    concat_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    for col in concat_df.columns:\n",
    "        concat_df.rename(columns={col: ''}, inplace=True)\n",
    "    tab_name_match = re.search(\"\\_\\d{2,}\", file).group().split('_')\n",
    "    tab_name = tab_name_match[-1]\n",
    "    return concat_df, tab_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233bdfb",
   "metadata": {},
   "source": [
    "<li>1) Create Company List</li>\n",
    "<li>2) Create Exception File List</li>\n",
    "<li>3) If file is in exception list, perform separate process, otherwise perform normal process.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87ddb3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahlsell's Income Statement master file has been created\n",
      "Dexko Global's Income Statement master file has been created\n",
      "Duff & Phelps's Income Statement master file has been created\n",
      "Hurtigruten's Income Statement master file has been created\n",
      "Impala's Income Statement master file has been created\n",
      "Informatica's Income Statement master file has been created\n",
      "Rocket Software's Income Statement master file has been created\n",
      "Ahlsell's Balance Sheet master file has been created\n",
      "Dexko Global's Balance Sheet master file has been created\n",
      "Duff & Phelps's Balance Sheet master file has been created\n",
      "Hurtigruten's Balance Sheet master file has been created\n",
      "Impala's Balance Sheet master file has been created\n",
      "Informatica's Balance Sheet master file has been created\n",
      "Rocket Software's Balance Sheet master file has been created\n",
      "Ahlsell's Cash Flow master file has been created\n",
      "Dexko Global's Cash Flow master file has been created\n",
      "Duff & Phelps's Cash Flow master file has been created\n",
      "Hurtigruten's Cash Flow master file has been created\n",
      "Impala's Cash Flow master file has been created\n",
      "Informatica's Cash Flow master file has been created\n",
      "Rocket Software's Cash Flow master file has been created\n"
     ]
    }
   ],
   "source": [
    "#companies = ['Rocket Software']\n",
    "companies = generate_company_list()\n",
    "exception_list = create_lists(companies)\n",
    "statement_list = ['Income Statement', 'Balance Sheet', 'Cash Flow']\n",
    "#statement_type = 'Income Statement'\n",
    "for statement_type in statement_list:\n",
    "    for company in companies:\n",
    "        if statement_type == 'Income Statement':\n",
    "            file_list = glob.glob(f\"C:/Users/curt.beck/Downloads/Cognaize/{company}[_]\" + ('[0-9]')*6 + \".xlsx\")\n",
    "        else:\n",
    "            file_list = glob.glob(f\"C:/Users/curt.beck/Downloads/Cognaize/{company}*.xlsx\")\n",
    "        excel_file = pd.ExcelWriter(f\"\\\\Users\\\\curt.beck\\\\Downloads\\\\Condensed_Cognaize\\\\{company}_{statement_type}.xlsx\", engine='xlsxwriter')\n",
    "        for file in file_list:\n",
    "            if file in exception_list and statement_type == 'Income Statement':\n",
    "                concat_df, tab_name_sep = sep_process(company, file, statement_type)\n",
    "                concat_df.to_excel(excel_file, sheet_name=tab_name_sep, index=False)\n",
    "            else:\n",
    "                sheet_names = pd.ExcelFile(file).sheet_names\n",
    "                sheet_name = filter_sheets(sheet_names, statement_type)\n",
    "                if len(sheet_name)==0:\n",
    "                    pass\n",
    "                elif len(sheet_name) > 1 and statement_type == 'Balance Sheet' and type(sheet_name) == list:\n",
    "                    concat_balance_df, tab_name = multiple_balance_sht(file, sheet_name)\n",
    "                    concat_balance_df.to_excel(excel_file, sheet_name=tab_name, index=False)\n",
    "                else:\n",
    "                    tab_name_match = re.search(\"\\_\\d+\", file).group().split('_')\n",
    "                    tab_name = tab_name_match[-1]\n",
    "                #sheet_name = filter_sheets(sheet_names, statement_type)\n",
    "                    try:\n",
    "                        df = pd.read_excel(file, sheet_name=sheet_name, header=None)\n",
    "                        df.rename(columns={'Unnamed: 0': ''}, inplace=True)\n",
    "                        #col_metadata = get_mtd_ytd_value2(file, sheet_name)\n",
    "                        #i = 0\n",
    "                        for col in df.columns:\n",
    "                                df.rename(columns={col: ''}, inplace=True)\n",
    "                        df.to_excel(excel_file, sheet_name=tab_name, index=False)\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "        excel_file.save()\n",
    "        print(f\"{company}'s {statement_type} master file has been created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
